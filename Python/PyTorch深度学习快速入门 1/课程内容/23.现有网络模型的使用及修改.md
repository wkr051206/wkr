# PyTorch预训练模型实战指南：VGG16与TorchVision深度解析

## 一、TorchVision核心模块解析

### 模型架构全景图

```python
graph TD
    A[TorchVision] --> B[Models]
    A --> C[Dataloaders]
    A --> D[Transforms]
    B --> E[Classification]
    B --> F[Detection]
    B --> G[Segmentation]
    E --> H[VGG/ResNet]
    F --> I[FasterRCNN]
    G --> J[DeepLabV3]
```

### 关键API速查表

|功能|API|参数说明|
|---|---|---|
|加载模型|`torchvision.models.vgg16(pretrained=True)`|`pretrained`: 预训练权重  <br>`progress`: 下载进度|
|数据集加载|`torchvision.datasets.CIFAR10(root, train, download)`|`root`: 存储路径  <br>`download`: 自动下载|
|数据转换|`torchvision.transforms.Compose([...])`|组合预处理操作|

## 二、VGG16架构深度剖析

### 网络结构详解

```python
VGG16(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    ... # 共13个卷积层
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)
```

### 特征提取原理

1. ​**​卷积块​**​：5组卷积+池化
    
    - 每组2-3个3×3卷积
        
    - 每组后接2×2最大池化
        
    
2. ​**​空间压缩​**​：224×224 → 7×7
    
3. ​**​全连接层​**​：3个FC层实现分类
    

## 三、预训练模型实战技巧

### 模型加载与修改

```python
import torchvision.models as models

# 加载预训练模型（不下载权重）
vgg = models.vgg16(pretrained=False)

# 加载预训练权重（需手动下载）
state_dict = torch.load('vgg16-397923af.pth')
vgg.load_state_dict(state_dict)

# 修改分类层（CIFAR10适配）
vgg.classifier[6] = nn.Linear(4096, 10)  # 1000→10类
```

### 迁移学习策略对比

|策略|训练参数|适用场景|代码示例|
|---|---|---|---|
|​**​特征提取​**​|仅训练分类层|小数据集|`for param in vgg.parameters(): param.requires_grad=False`|
|​**​微调​**​|训练所有层|大数据集|直接训练全模型|
|​**​部分微调​**​|训练后几层|中等数据集|`for param in vgg.features[:24]: param.requires_grad=False`|

## 四、CIFAR10数据集优化方案

### 小尺寸适配技巧

```python
# 修改VGG输入层（适配32×32输入）
vgg.features[0] = nn.Conv2d(3, 64, kernel_size=3, padding=1)

# 移除部分池化层（保持特征图尺寸）
vgg.features = nn.Sequential(*list(vgg.features.children())[:-5])
```

### 数据增强策略

```python
from torchvision import transforms

train_transform = transforms.Compose([
    transforms.RandomResizedCrop(32),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))
])
```

## 五、ImageNet替代方案

### 小型预训练数据集

|数据集|类别数|图像尺寸|下载命令|
|---|---|---|---|
|CIFAR10|10|32×32|`torchvision.datasets.CIFAR10()`|
|CIFAR100|100|32×32|`torchvision.datasets.CIFAR100()`|
|TinyImageNet|200|64×64|[手动下载](http://cs231n.stanford.edu/tiny-imagenet-200.zip)|

### 预训练权重获取

```python
# 从TorchHub加载
vgg = torch.hub.load('pytorch/vision', 'vgg16', pretrained=True)

# 从HuggingFace加载
from huggingface_hub import hf_hub_download
weights_path = hf_hub_download(repo_id="pytorch/models", filename="vgg16-397923af.pth")
```

## 六、完整训练示例

```python
import torch.optim as optim
from torchvision.datasets import CIFAR10

# 1. 准备数据
train_set = CIFAR10(root='./data', train=True, download=True, transform=train_transform)
train_loader = DataLoader(train_set, batch_size=128, shuffle=True)

# 2. 修改VGG模型
vgg = models.vgg16(pretrained=False)
vgg.classifier[6] = nn.Linear(4096, 10)

# 3. 优化器配置
optimizer = optim.SGD([
    {'params': vgg.features.parameters(), 'lr': 0.001},
    {'params': vgg.classifier.parameters(), 'lr': 0.01}
], momentum=0.9)

# 4. 训练循环
for epoch in range(100):
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        outputs = vgg(inputs)
        loss = F.cross_entropy(outputs, labels)
        loss.backward()
        optimizer.step()
```

## 七、模型评估与部署

### 准确率计算

```python
correct = 0
total = 0
with torch.no_grad():
    for images, labels in test_loader:
        outputs = vgg(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f'测试准确率: {100 * correct / total}%')
```

### ONNX导出部署

```python
# 导出模型
dummy_input = torch.randn(1, 3, 32, 32)
torch.onnx.export(vgg, dummy_input, "vgg_cifar.onnx")

# TensorRT加速
trt_model = torch2trt(vgg, [dummy_input])
```

## 八、高级技巧与最佳实践

### 1. 知识蒸馏

```python
# 教师模型（完整VGG）
teacher = models.vgg16(pretrained=True)
teacher.classifier[6] = nn.Linear(4096, 10)

# 学生模型（精简版）
student = models.mobilenet_v2(num_classes=10)

# 蒸馏损失
def distillation_loss(y, teacher_scores, T=3):
    return F.kl_div(F.log_softmax(y/T, dim=1), 
                    F.softmax(teacher_scores/T, dim=1)) * (T*T)
```

### 2. 特征可视化

```python
from torchvision.utils import make_grid

# 提取中间特征
features = []
def hook(module, input, output):
    features.append(output)

vgg.features[3].register_forward_hook(hook)  # 第一个卷积块后

# 可视化
with torch.no_grad():
    vgg(test_images)
    feature_grid = make_grid(features[0][:8], nrow=4, normalize=True)
    plt.imshow(feature_grid.permute(1,2,0))
```

### 3. 模型量化

```python
# 动态量化
quantized_model = torch.quantization.quantize_dynamic(
    vgg, {nn.Linear}, dtype=torch.qint8
)

# 静态量化
vgg.qconfig = torch.quantization.get_default_qconfig('fbgemm')
torch.quantization.prepare(vgg, inplace=True)
# ...校准...
torch.quantization.convert(vgg, inplace=True)
```

> ​**​实战建议​**​：对于CIFAR10任务，使用预训练VGG16微调可达到85%+准确率。工业部署建议转换为MobileNetV3等轻量模型，平衡精度与速度。