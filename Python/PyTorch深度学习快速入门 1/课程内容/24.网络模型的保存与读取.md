# PyTorch模型保存与加载核心技术指南

## 一、模型保存策略对比分析

### 两种核心方法对比

```python
graph TD
    A[模型保存方式] --> B[完整模型保存]
    A --> C[状态字典保存]
    B --> D[优点：加载简单]
    B --> E[缺点：文件大/依赖代码]
    C --> F[优点：文件小/灵活]
    C --> G[缺点：需模型定义]
```

### 详细参数对比表

|特性|完整模型保存 (`torch.save(model, path)`)|状态字典保存 (`torch.save(model.state_dict(), path)`)|
|---|---|---|
|​**​文件大小​**​|大（含结构+参数）|小（仅参数）|
|​**​加载速度​**​|快|稍慢（需重建结构）|
|​**​代码依赖​**​|强（需原始类定义）|弱（只需模型类）|
|​**​版本兼容​**​|差（PyTorch版本敏感）|好|
|​**​推荐指数​**​|★★☆|★★★★★|

## 二、状态字典保存最佳实践

### 完整保存流程

```python
import torch
import torchvision.models as models

# 1. 创建并训练模型
model = models.vgg16(pretrained=True)
# ...训练代码...

# 2. 保存状态字典（推荐）
torch.save({
    'epoch': 100,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'loss': loss,
}, 'model_checkpoint.pth')
```

### 文件结构解析

```python
checkpoint = torch.load('model_checkpoint.pth')
print(checkpoint.keys())
# 输出：dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'loss'])
```

## 三、模型加载技术详解

### 安全加载方案

```python
# 方案1：完整模型加载（不推荐）
# model = torch.load('full_model.pth')  # 需要原始类定义

# 方案2：状态字典加载（推荐）
model = models.vgg16()  # 新建模型结构
model.load_state_dict(torch.load('state_dict.pth'))
```

### 设备兼容处理

```python
# GPU保存 → CPU加载
device = torch.device('cpu')
model.load_state_dict(torch.load('gpu_model.pth', map_location=device))

# 多GPU保存 → 单GPU加载
model = nn.DataParallel(model)  # 训练时
# 加载时移除module前缀
state_dict = {k.replace('module.', ''): v for k,v in torch.load('model.pth').items()}
model.load_state_dict(state_dict)
```

## 四、自定义模型处理技巧

### 类定义管理方案

```python
# model_def.py
import torch.nn as nn

class CustomModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.layer = nn.Linear(10, 2)
    
    def forward(self, x):
        return self.layer(x)

# train.py
from model_def import CustomModel
model = CustomModel()
torch.save(model.state_dict(), 'custom_model.pth')

# infer.py
from model_def import CustomModel  # 必须导入类定义
model = CustomModel()
model.load_state_dict(torch.load('custom_model.pth'))
```

### 类注册系统（高级）

```python
# model_registry.py
_MODELS = {}

def register_model(name):
    def decorator(cls):
        _MODELS[name] = cls
        return cls
    return decorator

@register_model('my_model')
class CustomModel(nn.Module):
    ...

# 加载时
from model_registry import _MODELS
model = _MODELS['my_model']()
model.load_state_dict(...)
```

## 五、生产环境部署方案

### ONNX导出跨平台部署

```python
torch.onnx.export(
    model, 
    dummy_input, 
    "model.onnx",
    input_names=["input"],
    output_names=["output"],
    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}
)
```

### TorchScript序列化

```python
# 跟踪模式
script_model = torch.jit.trace(model, example_input)
script_model.save("model.pt")

# 脚本模式
script_model = torch.jit.script(model)
script_model.save("model.pt")
```

## 六、版本控制与实验管理

### 模型命名规范

```python
def get_model_filename(model_name, epoch, accuracy):
    return f"{model_name}_e{epoch}_acc{accuracy:.2f}.pth"

# 示例：vgg16_e100_acc0.85.pth
```

### 完整检查点管理

```python
checkpoint = {
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'scheduler_state_dict': scheduler.state_dict(),
    'best_acc': best_acc,
    'config': config  # 保存超参数
}
torch.save(checkpoint, f'checkpoint_epoch{epoch}.pth')
```

## 七、常见问题解决方案

### 错误处理表

|错误信息|原因|解决方案|
|---|---|---|
|`Missing key(s) in state_dict`|模型结构变化|使用`strict=False`加载|
|`Unexpected key(s)`|模型结构变化|过滤无关键值|
|`Can't pickle ...`|不可序列化对象|避免保存lambda函数|
|`CUDA out of memory`|加载时内存不足|使用`map_location='cpu'`|

### 安全加载代码

```python
def safe_load(model, checkpoint_path):
    state_dict = torch.load(checkpoint_path, map_location='cpu')
    
    # 处理不匹配键值
    model_state_dict = model.state_dict()
    matched_state_dict = {}
    
    for k, v in state_dict.items():
        if k in model_state_dict and v.shape == model_state_dict[k].shape:
            matched_state_dict[k] = v
        else:
            print(f"跳过不匹配键: {k}")
    
    model.load_state_dict(matched_state_dict, strict=False)
    return model
```

## 八、GPU训练与部署工作流

### 完整GPU训练流程

```python
# 1. 设备设置
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

# 2. 训练循环
for epoch in range(epochs):
    for data, target in train_loader:
        data, target = data.to(device), target.to(device)
        # ...训练步骤...
    
    # 3. 保存检查点
    if epoch % 10 == 0:
        torch.save({
            'model': model.state_dict(),
            'optimizer': optimizer.state_dict()
        }, f'checkpoint_{epoch}.pth')

# 4. 最终模型保存
torch.save(model.state_dict(), 'final_model.pth')
```

### 生产部署优化

```python
# 量化压缩
quantized_model = torch.quantization.quantize_dynamic(
    model, {nn.Linear}, dtype=torch.qint8
)

# 转换为TensorRT
from torch2trt import torch2trt
trt_model = torch2trt(model, [dummy_input])
```

> ​**​最佳实践​**​：在研发阶段使用状态字典保存，生产部署转换为TorchScript或ONNX格式。使用命名规范管理版本，每次保存包含完整训练上下文（优化器/学习率等）。